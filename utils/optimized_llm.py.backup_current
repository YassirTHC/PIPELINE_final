#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üöÄ SYST√àME LLM MINIMALISTE - PROMPTS G√âN√âRIQUES + SP√âCIALISATION PIPELINE
Bas√© sur l'analyse brillante de l'utilisateur : prompts simples + sp√©cialisation intelligente
"""

import requests
import json
import time
import logging
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class OptimizedLLM:
    """Syst√®me LLM avec prompts minimalistes et sp√©cialisation via pipeline"""
    
    def __init__(self, base_url: str = "http://localhost:11434", model: str = "gemma3:4b"):
        self.base_url = base_url.rstrip("/")
        self.model = model
        self.timeout = 120  # 2 minutes par d√©faut
        
    def _call_llm(self, prompt: str, temperature: float = 0.1, max_tokens: int = 100) -> Tuple[bool, str]:
        """Appel LLM simple avec gestion d'erreur"""
        try:
            payload = {
                "model": self.model,
                "prompt": prompt,
                "temperature": temperature,
                "stream": False
            }
            
            start_time = time.time()
            response = requests.post(
                f"{self.base_url}/api/generate",
                json=payload,
                timeout=self.timeout
            )
            end_time = time.time()
            
            if response.status_code == 200:
                result = response.json()
                response_text = result.get('response', '').strip()
                duration = end_time - start_time
                
                logger.info(f"‚úÖ LLM r√©ussi en {duration:.1f}s - {len(response_text)} caract√®res")
                return True, response_text
            else:
                logger.error(f"‚ùå Erreur HTTP: {response.status_code}")
                return False, ""
                
        except requests.exceptions.Timeout:
            logger.error(f"‚è±Ô∏è Timeout apr√®s {self.timeout}s")
            return False, ""
        except Exception as e:
            logger.error(f"‚ùå Erreur LLM: {str(e)}")
            return False, ""
    
    def _extract_json(self, text: str) -> Optional[Dict[str, Any]]:
        """Extraction robuste du JSON depuis la r√©ponse LLM"""
        try:
            # Nettoyer et extraire le JSON
            text = text.strip()
            start_idx = text.find("{")
            end_idx = text.rfind("}")
            
            if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
                json_str = text[start_idx:end_idx + 1]
                return json.loads(json_str)
            else:
                logger.warning("‚ö†Ô∏è Aucun JSON trouv√© dans la r√©ponse")
                return None
                
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Erreur parsing JSON: {e}")
            return None
    
    def generate_keywords(self, transcript: str, max_keywords: int = 15) -> Tuple[bool, List[str]]:
        """G√©n√©ration de mots-cl√©s avec prompt minimaliste g√©n√©rique"""
        
        # üéØ PROMPT MINIMALISTE (votre approche parfaite)
        prompt = f"""Extract {max_keywords} to {max_keywords + 5} relevant single-word keywords from the transcript.
Do not invent unrelated terms.
Output JSON only: {{"keywords":["word1","word2", "..."]}}

Transcript: {transcript}

JSON:"""
        
        logger.info(f"üéØ G√©n√©ration mots-cl√©s avec prompt minimaliste ({len(prompt)} caract√®res)")
        
        success, response = self._call_llm(prompt)
        if not success:
            return False, []
        
        # Extraction et validation
        json_data = self._extract_json(response)
        if not json_data:
            return False, []
        
        keywords = json_data.get("keywords", [])
        if not keywords or not isinstance(keywords, list):
            logger.warning("‚ö†Ô∏è Aucun mot-cl√© valide trouv√©")
            return False, []
        
        # Nettoyage et validation
        clean_keywords = []
        seen = set()
        generic = {"what","over","your","look","when","learn","about","thing","things","people","really","going","want","need","make","take","time","back","good","best","more","most","very","that","this","those","these"}
        for kw in keywords:
            if isinstance(kw, str) and kw.strip():
                clean_kw = kw.strip().lower()
                if len(clean_kw) <= 2:
                    continue
                if clean_kw in generic:
                    continue
                if not clean_kw.isalpha():
                    continue
                if clean_kw in seen:
                    continue
                seen.add(clean_kw)
                clean_keywords.append(clean_kw)
        
        # Prioritize specificity by length and uniqueness
        clean_keywords.sort(key=lambda k: (-len(k), k))
        
        logger.info(f"‚úÖ {len(clean_keywords)} mots-cl√©s g√©n√©r√©s avec succ√®s")
        return True, clean_keywords[:max_keywords]
    
    def generate_title_hashtags(self, transcript: str) -> Tuple[bool, Dict[str, Any]]:
        """G√©n√©ration titre + hashtags avec prompt minimaliste"""
        
        # üéØ PROMPT MINIMALISTE pour titre + hashtags
        prompt = f"""Generate a title and hashtags from this transcript.
Output JSON only: {{"title": "Title here", "hashtags": ["#tag1", "#tag2", "..."]}}

Transcript: {transcript}

JSON:"""
        
        logger.info(f"üéØ G√©n√©ration titre + hashtags avec prompt minimaliste ({len(prompt)} caract√®res)")
        
        success, response = self._call_llm(prompt)
        if not success:
            return False, {}
        
        # Extraction et validation
        json_data = self._extract_json(response)
        if not json_data:
            return False, {}
        
        title = json_data.get("title", "").strip()
        hashtags = json_data.get("hashtags", [])
        
        if not title:
            logger.warning("‚ö†Ô∏è Aucun titre valide trouv√©")
            return False, {}
        
        # Nettoyage des hashtags
        clean_hashtags = []
        for tag in hashtags:
            if isinstance(tag, str) and tag.strip():
                clean_tag = tag.strip()
                if not clean_tag.startswith("#"):
                    clean_tag = f"#{clean_tag}"
                clean_hashtags.append(clean_tag)
        
        result = {
            "title": title,
            "hashtags": clean_hashtags
        }
        
        logger.info(f"‚úÖ Titre et {len(clean_hashtags)} hashtags g√©n√©r√©s avec succ√®s")
        return True, result
    
    def generate_complete_metadata(self, transcript: str) -> Tuple[bool, Dict[str, Any]]:
        """G√©n√©ration compl√®te : titre, description, hashtags, mots-cl√©s"""
        
        # üéØ PROMPT MINIMALISTE pour m√©tadonn√©es compl√®tes
        prompt = f"""Generate title, description, hashtags, and keywords from this transcript.
Output JSON only: {{"title": "Title", "description": "Description", "hashtags": ["#tag1"], "keywords": ["word1"]}}

Transcript: {transcript}

JSON:"""
        
        logger.info(f"üéØ G√©n√©ration m√©tadonn√©es compl√®tes avec prompt minimaliste ({len(prompt)} caract√®res)")
        
        success, response = self._call_llm(prompt)
        if not success:
            return False, {}
        
        # Extraction et validation
        json_data = self._extract_json(response)
        if not json_data:
            return False, {}
        
        # Extraction des champs
        title = json_data.get("title", "").strip()
        description = json_data.get("description", "").strip()
        hashtags = json_data.get("hashtags", [])
        keywords = json_data.get("keywords", [])
        
        # Validation des champs obligatoires
        if not title:
            logger.warning("‚ö†Ô∏è Aucun titre valide trouv√©")
            return False, {}
        
        # Nettoyage des hashtags
        clean_hashtags = []
        for tag in hashtags:
            if isinstance(tag, str) and tag.strip():
                clean_tag = tag.strip()
                if not clean_tag.startswith("#"):
                    clean_tag = f"#{clean_tag}"
                clean_hashtags.append(clean_tag)
        
        # Nettoyage des mots-cl√©s
        clean_keywords = []
        for kw in keywords:
            if isinstance(kw, str) and kw.strip():
                clean_kw = kw.strip().lower()
                if len(clean_kw) > 2:
                    clean_keywords.append(clean_kw)
        
        result = {
            "title": title,
            "description": description,
            "hashtags": clean_hashtags,
            "keywords": clean_keywords
        }
        
        logger.info(f"‚úÖ M√©tadonn√©es compl√®tes g√©n√©r√©es : titre, description, {len(clean_hashtags)} hashtags, {len(clean_keywords)} mots-cl√©s")
        return True, result
    
    def generate_broll_keywords_and_queries(self, transcript: str, max_keywords: int = 15) -> Tuple[bool, Dict[str, Any]]:
        """
        üéØ NOUVEAU: G√©n√©ration sp√©cialis√©e pour B-roll
        Produit explicitement broll_keywords + search_queries
        """
        
        # üéØ PROMPT MINIMALISTE sp√©cialis√© B-roll OPTIMIS√â pour sp√©cificit√© visuelle
        prompt = f"""Extract {max_keywords} visually-specific B-roll keywords and {max_keywords} search queries from the transcript.
Output JSON only: {{"broll_keywords":["..."], "search_queries":["..."]}}

üéØ B-roll keywords: Generate VISUALLY-SPECIFIC terms that represent actual visual elements.
Focus on concrete, searchable terms for stock footage APIs.

Examples of GOOD B-roll keywords:
- "doctor_office" (not just "office")
- "therapy_session" (not just "therapy")
- "brain_scan" (not just "brain")
- "patient_consultation" (not just "patient")
- "medical_charts" (not just "charts")
- "stethoscope_examination" (not just "examination")

Examples of BAD B-roll keywords (too generic):
- "therapy", "healing", "treatment" (too abstract)
- "office", "room", "building" (too generic)
- "person", "people", "man" (not specific enough)

üîç Search queries: Generate ready-to-use search phrases (2-4 words each) for Pexels/Pixabay:
- "doctor office consultation"
- "therapy session closeup"
- "brain scan medical"
- "patient therapist interaction"

Transcript: {transcript}

JSON:"""
        
        logger.info(f"üéØ G√©n√©ration B-roll avec prompt minimaliste ({len(prompt)} caract√®res)")
        
        success, response = self._call_llm(prompt)
        if not success:
            return False, {}
        
        # Extraction et validation
        json_data = self._extract_json(response)
        if not json_data:
            return False, {}
        
        # Extraction des champs B-roll
        broll_keywords = json_data.get("broll_keywords", [])
        search_queries = json_data.get("search_queries", [])
        
        # Validation des champs
        if not broll_keywords or not search_queries:
            logger.warning("‚ö†Ô∏è Champs B-roll manquants dans la r√©ponse")
            return False, {}
        
        # Nettoyage des mots-cl√©s B-roll
        clean_broll_keywords = []
        for kw in broll_keywords:
            if isinstance(kw, str) and kw.strip():
                clean_kw = kw.strip().lower()
                if len(clean_kw) > 2:
                    clean_broll_keywords.append(clean_kw)
        
        # Nettoyage des requ√™tes de recherche
        clean_search_queries = []
        for query in search_queries:
            if isinstance(query, str) and query.strip():
                clean_query = query.strip()
                if len(clean_query) <= 25:  # Limite pour les APIs
                    clean_search_queries.append(clean_query)
        
        result = {
            "broll_keywords": clean_broll_keywords[:max_keywords],
            "search_queries": clean_search_queries[:max_keywords]
        }
        
        logger.info(f"‚úÖ B-roll g√©n√©r√© : {len(clean_broll_keywords)} mots-cl√©s, {len(clean_search_queries)} requ√™tes")
        return True, result
    
    def generate_metadata_with_broll(self, transcript: str) -> Tuple[bool, Dict[str, Any]]:
        """
        üéØ NOUVEAU: G√©n√©ration compl√®te avec m√©tadonn√©es + B-roll
        Combine toutes les informations n√©cessaires
        """
        
        # üéØ PROMPT MINIMALISTE complet avec B-roll OPTIMIS√â
        prompt = f"""Generate complete metadata and B-roll information from this transcript.
Output JSON only: {{
    "title": "Title",
    "description": "Description", 
    "hashtags": ["#tag1"],
    "keywords": ["word1"],
    "broll_keywords": ["visual_word1"],
    "search_queries": ["2-4 word query1"]
}}

B-roll keywords: single visual words for stock footage search.
Search queries: 2-4 word phrases ready for Pexels/Pixabay APIs.

Transcript: {transcript}

JSON:"""
        
        logger.info(f"üéØ G√©n√©ration compl√®te avec B-roll ({len(prompt)} caract√®res)")
        
        success, response = self._call_llm(prompt)
        if not success:
            return False, {}
        
        # Extraction et validation
        json_data = self._extract_json(response)
        if not json_data:
            return False, {}
        
        # Extraction de tous les champs
        title = json_data.get("title", "").strip()
        description = json_data.get("description", "").strip()
        hashtags = json_data.get("hashtags", [])
        keywords = json_data.get("keywords", [])
        broll_keywords = json_data.get("broll_keywords", [])
        search_queries = json_data.get("search_queries", [])
        
        # Validation des champs obligatoires
        if not title:
            logger.warning("‚ö†Ô∏è Aucun titre valide trouv√©")
            return False, {}
        
        # Nettoyage des hashtags
        clean_hashtags = []
        for tag in hashtags:
            if isinstance(tag, str) and tag.strip():
                clean_tag = tag.strip()
                if not clean_tag.startswith("#"):
                    clean_tag = f"#{clean_tag}"
                clean_hashtags.append(clean_tag)
        
        # Nettoyage des mots-cl√©s
        clean_keywords = []
        for kw in keywords:
            if isinstance(kw, str) and kw.strip():
                clean_kw = kw.strip().lower()
                if len(clean_kw) > 2:
                    clean_keywords.append(clean_kw)
        
        # Nettoyage des mots-cl√©s B-roll
        clean_broll_keywords = []
        for kw in broll_keywords:
            if isinstance(kw, str) and kw.strip():
                clean_kw = kw.strip().lower()
                if len(clean_kw) > 2:
                    clean_broll_keywords.append(clean_kw)
        
        # Nettoyage des requ√™tes de recherche
        clean_search_queries = []
        for query in search_queries:
            if isinstance(query, str) and query.strip():
                clean_query = query.strip()
                if len(clean_query) <= 25:
                    clean_search_queries.append(clean_query)
        
        result = {
            "title": title,
            "description": description,
            "hashtags": clean_hashtags,
            "keywords": clean_keywords,
            "broll_keywords": clean_broll_keywords,
            "search_queries": clean_search_queries
        }
        
        logger.info(f"‚úÖ M√©tadonn√©es compl√®tes avec B-roll : titre, description, {len(clean_hashtags)} hashtags, {len(clean_keywords)} mots-cl√©s, {len(clean_broll_keywords)} B-roll, {len(clean_search_queries)} requ√™tes")
        return True, result

# === FONCTIONS UTILITAIRES POUR L'INT√âGRATION ===

def create_optimized_llm(base_url: str = None, model: str = None) -> OptimizedLLM:
    """Factory pour cr√©er une instance LLM optimis√©e"""
    
    # D√©tection automatique de l'URL et du mod√®le
    if not base_url:
        # Essayer Ollama en premier
        try:
            response = requests.get("http://localhost:11434/api/tags", timeout=5)
            if response.status_code == 200:
                base_url = "http://localhost:11434"
                logger.info("‚úÖ Ollama d√©tect√© sur localhost:11434")
            else:
                base_url = "http://localhost:1234"  # LM Studio par d√©faut
                logger.info("‚ö†Ô∏è Ollama non disponible, utilisation LM Studio par d√©faut")
        except:
            base_url = "http://localhost:1234"
            logger.info("‚ö†Ô∏è Aucun LLM local d√©tect√©, utilisation LM Studio par d√©faut")
    
    if not model:
        # Mod√®le par d√©faut selon la disponibilit√©
        if "11434" in base_url:  # Ollama
            model = "gemma3:4b"  # Mod√®le recommand√©
        else:  # LM Studio
            model = "default"
    
    return OptimizedLLM(base_url, model)

def generate_keywords_for_pipeline(transcript: str, max_keywords: int = 15) -> Tuple[bool, List[str]]:
    """Fonction utilitaire pour int√©gration directe dans le pipeline"""
    llm = create_optimized_llm()
    return llm.generate_keywords(transcript, max_keywords)

def generate_metadata_for_pipeline(transcript: str) -> Tuple[bool, Dict[str, Any]]:
    """Fonction utilitaire pour int√©gration directe dans le pipeline"""
    llm = create_optimized_llm()
    return llm.generate_complete_metadata(transcript)

def generate_broll_for_pipeline(transcript: str, max_keywords: int = 15) -> Tuple[bool, Dict[str, Any]]:
    """üéØ NOUVEAU: Fonction utilitaire pour B-roll"""
    llm = create_optimized_llm()
    return llm.generate_broll_keywords_and_queries(transcript, max_keywords)

def generate_complete_with_broll(transcript: str) -> Tuple[bool, Dict[str, Any]]:
    """üéØ NOUVEAU: Fonction utilitaire pour m√©tadonn√©es compl√®tes avec B-roll"""
    llm = create_optimized_llm()
    return llm.generate_metadata_with_broll(transcript)

# === TEST RAPIDE ===
if __name__ == "__main__":
    print("üß† Test du syst√®me LLM optimis√©...")
    
    # Test avec un transcript simple
    test_transcript = "EMDR therapy utilizes bilateral stimulation to process traumatic memories. The therapist guides the patient through eye movements while recalling distressing events."
    
    llm = create_optimized_llm()
    
    # Test mots-cl√©s
    print("\nüéØ Test g√©n√©ration mots-cl√©s...")
    success, keywords = llm.generate_keywords(test_transcript, 10)
    if success:
        print(f"‚úÖ Mots-cl√©s g√©n√©r√©s: {keywords}")
    else:
        print("‚ùå √âchec g√©n√©ration mots-cl√©s")
    
    # Test m√©tadonn√©es compl√®tes
    print("\nüéØ Test g√©n√©ration m√©tadonn√©es compl√®tes...")
    success, metadata = llm.generate_complete_metadata(test_transcript)
    if success:
        print(f"‚úÖ M√©tadonn√©es g√©n√©r√©es:")
        for key, value in metadata.items():
            print(f"   {key}: {value}")
    else:
        print("‚ùå √âchec g√©n√©ration m√©tadonn√©es")
    
    # üéØ NOUVEAU: Test B-roll
    print("\nüéØ Test g√©n√©ration B-roll...")
    success, broll_data = llm.generate_broll_keywords_and_queries(test_transcript, 8)
    if success:
        print(f"‚úÖ B-roll g√©n√©r√©:")
        print(f"   Mots-cl√©s: {broll_data['broll_keywords']}")
        print(f"   Requ√™tes: {broll_data['search_queries']}")
    else:
        print("‚ùå √âchec g√©n√©ration B-roll")
    
    # üéØ NOUVEAU: Test complet avec B-roll
    print("\nüéØ Test g√©n√©ration compl√®te avec B-roll...")
    success, complete_data = llm.generate_metadata_with_broll(test_transcript)
    if success:
        print(f"‚úÖ Donn√©es compl√®tes g√©n√©r√©es:")
        for key, value in complete_data.items():
            print(f"   {key}: {value}")
    else:
        print("‚ùå √âchec g√©n√©ration compl√®te") 